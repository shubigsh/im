# -*- coding: utf-8 -*-
"""Copy of Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ww9HvKaEB-PjJYBfPdCK3k2fkXW_iu4w
"""

!pip install easyocr
!pip install --upgrade googletrans==4.0.0-rc1
!pip install gTTS

import easyocr
from googletrans import Translator
from gtts import gTTS
from IPython.display import Audio
from PIL import Image, ImageDraw

!pip install --upgrade googletrans==4.0.0-rc1

# Step 1: Perform OCR on the image to extract the text
def perform_ocr(image_path):
    reader = easyocr.Reader(['en'])
    bounds = reader.readtext(image_path, add_margin=0.55, width_ths=0.7, link_threshold=0.8, decoder='beamsearch', blocklist='=-')
    return bounds

# Step 2: Translate the extracted text to the desired language
def translate_text(text, dest_lang):
    translator = Translator()
    translation = translator.translate(text, dest=dest_lang)
    return translation.text

# Step 3: Convert translated text to speech and play the audio
def text_to_speech(text, lang):
    tts = gTTS(text=text, lang=lang)
    tts.save('output.mp3')
    return Audio('output.mp3')

# Step 4: Display the extracted text and translated text
def display_text(text, translation):
    print('Extracted Text:', text)
    print('Translation:', translation)

# Step 5: Draw bounding boxes around the text in the image
def draw_boxes(image_path, bounds):
    im = Image.open(image_path)
    draw = ImageDraw.Draw(im)

    for bound in bounds:
        points = [tuple(point) for point in bound[0]]
        draw.polygon(points, outline='yellow')

    im.show()

# Main function to process the image
def process_image(image_path, dest_lang='en'):
    # Step 1: Perform OCR on the image
    bounds = perform_ocr(image_path)

    # Step 2: Extract text from bounds
    text = ' '.join([bound[1] for bound in bounds])

    # Step 3: Translate the text to the desired language
    translation = translate_text(text, dest_lang)

    # Step 4: Display the extracted text and translation
    display_text(text, translation)

    # Step 5: Draw bounding boxes around the text in the image
    draw_boxes(image_path, bounds)

    # Step 6: Convert translation to speech and play the audio
    audio = text_to_speech(translation, dest_lang)
    return audio

# Call the process_image function with the image path
image_path = "/content/chinese image.jfif"#replace your image path
audio_output = process_image(image_path, dest_lang='en')

# Play the audio
audio_output

import easyocr
from googletrans import Translator
from gtts import gTTS
from IPython.display import Audio
from PIL import Image, ImageDraw

# Install or upgrade necessary libraries
!pip install --upgrade googletrans==4.0.0-rc1

# Step 1: Perform OCR on the image to extract the text
def perform_ocr(image_path):
    reader = easyocr.Reader(['en'])
    bounds = reader.readtext(image_path, add_margin=0.55, width_ths=0.7, link_threshold=0.8, decoder='beamsearch', blocklist='=-')
    return bounds

# Step 2: Translate the extracted text to the desired language
def translate_text(text, dest_lang):
    translator = Translator()
    try:
        translation = translator.translate(text, dest=dest_lang)
        return translation.text
    except Exception as e:
        print(f"Translation Error for language '{dest_lang}': {e}")
        return "Translation Failed"

# Step 3: Convert translated text to speech and play the audio
def text_to_speech(text, lang):
    tts = gTTS(text=text, lang=lang)
    tts.save('output.mp3')
    return Audio('output.mp3')

# Step 4: Display the extracted text and translated text
def display_text(text, translations):
    print('Extracted Text:', text)
    print('Translations:')
    for lang, translation in translations.items():
        print(f"{lang}: {translation}")


# Step 5: Draw bounding boxes around the text in the image
def draw_boxes(image_path, bounds):
    im = Image.open(image_path)
    draw = ImageDraw.Draw(im)

    for bound in bounds:
        points = [tuple(point) for point in bound[0]]
        draw.polygon(points, outline='yellow')

    im.show()


# Main function to process the image
def process_image(image_path, dest_languages=['en']):
    # Step 1: Perform OCR on the image
    bounds = perform_ocr(image_path)

    # Step 2: Extract text from bounds
    text = ' '.join([bound[1] for bound in bounds])

    # Step 3: Translate the text to the desired languages
    translations = {}
    for dest_lang in dest_languages:
        translation = translate_text(text, dest_lang)
        translations[dest_lang] = translation

    # Step 4: Display the extracted text and translations
    display_text(text, translations)

    # Step 5: Draw bounding boxes around the text in the image
    draw_boxes(image_path, bounds)

    # Step 6: Convert translations to speech and play the audio for each language
    audio_outputs = []
    for lang, translation in translations.items():
        audio = text_to_speech(translation, lang)
        audio_outputs.append(audio)

    return audio_outputs

# Call the process_image function with the image path and desired languages
image_path = "/content/chinese image.jfif"  # Replace with the actual image path
desired_languages = ['en', 'fr', 'es','ta']  # Add other desired languages here
audio_outputs = process_image(image_path, dest_languages=desired_languages)

# Play the audio for each translation
for audio_output in audio_outputs:
    display(audio_output)